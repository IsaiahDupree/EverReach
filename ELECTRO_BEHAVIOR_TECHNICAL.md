# Electro-Behavior Models ‚Äî Technical Specification

**Version**: 0.1.0  
**Date**: October 22, 2025  
**Status**: Design & Prototype

---

## üéØ Mathematical Foundations

### State-Space Model (SSM)

The core dynamical system running at daily cadence:

#### **Dynamics**
```
x_{t+1} = A x_t + B u_t + E d_t + w_t
```

Where:
- `x_t ‚àà ‚Ñù^nx`: Hidden state (habit, momentum, latent engagement)
- `u_t ‚àà ‚Ñù^nu`: Control inputs (rollout %, promo voltage, price, copy)
- `d_t ‚àà ‚Ñù^nd`: Disturbances (seasonality, outages, OS changes)
- `w_t ~ N(0, Q)`: Process noise
- `A ‚àà ‚Ñù^(nx √ó nx)`: State transition matrix
- `B ‚àà ‚Ñù^(nx √ó nu)`: Input matrix
- `E ‚àà ‚Ñù^(nx √ó nd)`: Disturbance matrix
- `Q ‚àà ‚Ñù^(nx √ó nx)`: Process noise covariance

#### **Observations (KPIs)**
```
y_t = C x_t + D u_t + v_t
```

Where:
- `y_t ‚àà ‚Ñù^ny`: Observed KPIs (DAU, retention, revenue, latency)
- `v_t ~ N(0, R)`: Observation noise
- `C ‚àà ‚Ñù^(ny √ó nx)`: Observation matrix
- `D ‚àà ‚Ñù^(ny √ó nu)`: Feedthrough matrix
- `R ‚àà ‚Ñù^(ny √ó ny)`: Observation noise covariance

#### **Typical Dimensions**
- `nx = 4`: habit_state, momentum, engagement_level, latency_state
- `nu = 4`: rollout_pct, promo_voltage, price_index, copy_score
- `ny = 4`: daily_active_users, retention_d7, revenue_usd, latency_p95_ms
- `nd = 2`: day_of_week_seasonal, monthly_seasonal

---

## üìä KPI Mapping

### Inputs (u_t)

| Variable | Range | Unit | Description |
|----------|-------|------|-------------|
| `rollout_pct` | [0, 1] | fraction | Feature flag rollout percentage |
| `promo_voltage` | [0, 1] | normalized | Motivation stimulus (promo intensity) |
| `price_index` | [0.8, 1.2] | ratio | Price relative to baseline (1.0 = base) |
| `copy_score` | [0, 1] | normalized | Copy effectiveness score |

### Outputs (y_t)

| KPI | Unit | Description | Typical Range |
|-----|------|-------------|---------------|
| `daily_active_users` | count | DAU | [1k, 100k] |
| `retention_d7` | fraction | 7-day retention rate | [0.2, 0.6] |
| `revenue_usd` | USD | Daily revenue | [0, 50k] |
| `latency_p95_ms` | milliseconds | p95 latency | [50, 500] |

### Disturbances (d_t)

| Variable | Range | Description |
|----------|-------|-------------|
| `day_of_week` | [0, 6] | Day of week effect (0=Mon, 6=Sun) |
| `monthly_cycle` | [0, 1] | Monthly billing cycle effect |
| `outage_flag` | {0, 1} | Service outage indicator |

---

## üßÆ RC Retention Model

### Formula
```
R(t) = R_‚àû + (R_0 - R_‚àû) e^(-t/RC)
```

Where:
- `R(t)`: Retention rate at day t
- `R_0`: Initial retention (day 0)
- `R_‚àû`: Asymptotic retention (long-term)
- `RC`: Time constant (days to habit)
- `t`: Days since signup

### Interpretation

| Parameter | Physical Analogy | Product Meaning | Typical Value |
|-----------|------------------|-----------------|---------------|
| `R` | Resistance | Onboarding friction | [0.5, 5.0] |
| `C` | Capacitance | Habit formation capacity | [5, 60] days |
| `RC` | Time constant | Time to establish habit | [10, 90] days |
| `1/R` | Conductance | Ease of conversion | [0.2, 2.0] |

### Cohort Examples

```python
# Power users: low friction, fast habit
R = 0.8, C = 12, RC = 9.6 days ‚Üí Quick habituation

# Casual users: high friction, slow habit  
R = 3.2, C = 45, RC = 144 days ‚Üí Slow habituation

# Churned segment: high friction, no habit
R = 5.0, C = 5, RC = 25 days ‚Üí Never stuck
```

---

## üéõÔ∏è Control & Optimization

### Model Predictive Control (MPC)

**Objective**: Optimize future trajectory over horizon H days

```
minimize: ‚àë_{k=0}^{H-1} [(y_k - y_ref)^T Q (y_k - y_ref) + u_k^T R u_k]

subject to:
  x_{k+1} = A x_k + B u_k
  y_k = C x_k + D u_k
  u_min ‚â§ u_k ‚â§ u_max
  y_k[latency_idx] ‚â§ latency_max
  ‚àë_k budget_coeff^T u_k ‚â§ budget_weekly
```

**Parameters**:
- `Q ‚àà ‚Ñù^(ny √ó ny)`: KPI tracking weight (diagonal)
- `R ‚àà ‚Ñù^(nu √ó nu)`: Input cost weight (diagonal)
- `H`: Horizon (typically 7-28 days)
- `y_ref`: Target KPIs
- `u_min, u_max`: Input bounds
- `latency_max`: Hard latency constraint (e.g., 250ms)
- `budget_weekly`: Weekly spend limit (USD)

**Solver**: OSQP (Operator Splitting QP) via CVXPY
- Convex problem ‚Üí global optimum
- Fast: ~10-50ms for H=7, nx=4, nu=4
- Warm-start capable for real-time replan

### Constrained Bandits

**Algorithm**: Linear Thompson Sampling with Lagrangian penalties

**Context**: `x = [1, rollout_pct, promo_voltage, price_index, copy_score, last_dau, last_latency]`

**Posterior**: `Œ∏ ~ N(Œº, Œ£)` updated via Bayesian linear regression

**Action Selection**:
```python
1. Sample Œ∏ from posterior
2. For each action a: compute reward = x_a^T Œ∏
3. Pick a* = argmax reward
4. Simulate forward with a* to get y_pred
5. Check guardrails: ok, violations = enforce_guardrails(y_pred, guards)
6. If ok: execute a*; else: try next best
```

**Update** (after observing reward r):
```
Œ£^{-1}_new = Œ£^{-1}_old + (1/œÉ^2) x x^T
Œº_new = Œ£_new (Œ£^{-1}_old Œº_old + (1/œÉ^2) x r)
```

---

## üìà Estimation & Learning

### Kalman Filter (State Estimation)

**Predict**:
```
Œº_{t|t-1} = A Œº_{t-1|t-1} + B u_t
Œ£_{t|t-1} = A Œ£_{t-1|t-1} A^T + Q
```

**Update**:
```
K_t = Œ£_{t|t-1} C^T (C Œ£_{t|t-1} C^T + R)^{-1}
Œº_{t|t} = Œº_{t|t-1} + K_t (y_t - C Œº_{t|t-1} - D u_t)
Œ£_{t|t} = (I - K_t C) Œ£_{t|t-1}
```

### Expectation-Maximization (Parameter Learning)

**E-Step**: Kalman filter + RTS smoother ‚Üí smoothed states `Œº_s, Œ£_s`

**M-Step**: Update A, B, C, D, Q, R via sufficient statistics

```
# State transition: x_{t+1} ‚âà A x_t + B u_t
X_t = [Œº_s[:-1], u[:-1]]^T  # (nx+nu, T-1)
X_next = Œº_s[1:]^T           # (nx, T-1)
W = X_next @ X_t^T @ (X_t @ X_t^T + ŒªI)^{-1}
A = W[:, :nx]
B = W[:, nx:]

# Observation: y_t ‚âà C x_t + D u_t
Xy = [Œº_s, u]^T              # (nx+nu, T)
Wy = y^T @ Xy^T @ (Xy @ Xy^T + ŒªI)^{-1}
C = Wy[:, :nx]
D = Wy[:, nx:]

# Noise covariances
Q = Cov(x_{t+1} - A x_t - B u_t)
R = Cov(y_t - C x_t - D u_t)
```

**Convergence**: Typically 10-30 iterations, monitor log-likelihood

**Diagnostics**:
- RMSE: `sqrt(mean((y_pred - y_true)^2))`
- R¬≤: `1 - SS_res / SS_tot`
- Parameter stability: track `||Œ∏_new - Œ∏_old||`

### Online Updates (Recursive Least Squares)

For real-time adaptation with forgetting factor Œª:

```
P_{t+1} = (1/Œª) (P_t - P_t x x^T P_t / (Œª + x^T P_t x))
Œ∏_{t+1} = Œ∏_t + P_{t+1} x (r - x^T Œ∏_t)
```

Typical Œª = 0.99 (1% forgetting per day)

---

## üî¨ Causal Inference

### Doubly-Robust (DR) Learner

**Goal**: Estimate individual treatment effect `œÑ(x) = E[Y(1) - Y(0) | X=x]`

**Algorithm**:
1. **Propensity Model**: `œÄ(x) = P(T=1 | X=x)` via logistic regression
2. **Outcome Models**: 
   - `Œº_0(x) = E[Y | T=0, X=x]` via Ridge on control group
   - `Œº_1(x) = E[Y | T=1, X=x]` via Ridge on treatment group
3. **AIPW Pseudo-Outcome**:
   ```
   œà = (T(Y - Œº_1(X)))/œÄ(X) - ((1-T)(Y - Œº_0(X)))/(1-œÄ(X)) + (Œº_1(X) - Œº_0(X))
   ```
4. **Meta-Learner**: `œÑ(x) = E[œà | X=x]` via Ridge

**Properties**:
- Doubly robust: consistent if *either* œÄ or Œº is correct
- Lower variance than simple difference-in-means
- Works with observational data (post-hoc A/B analysis)

**Usage**:
```python
dr = DRLearner().fit(X, treatment, outcome)
uplift = dr.predict_uplift(X_new)
recommend = (uplift >= min_threshold).astype(int)
```

---

## üõ°Ô∏è Guardrails & Safety

### Constraint Types

#### 1. **Hard Constraints** (MPC)
```
latency_p95 ‚â§ 250ms
budget_weekly ‚â§ $3000
rollout_pct ‚àà [0, 1]
```

#### 2. **Chance Constraints** (Probabilistic)
```
P(retention_d7 ‚â• 0.24) ‚â• 0.9
```

Implemented via:
- Scenario sampling (Monte Carlo)
- Analytical bounds (if Gaussian)
- Conservative estimates (lower confidence bound)

#### 3. **Soft Penalties** (Lagrangian)
```
Cost = reward - Œª_latency * max(0, latency - 250)
              - Œª_budget * max(0, spend - 3000)
```

### Sequential Testing

**Alpha Spending**: Allocate Type I error budget over time
```
Œ±_spent(t) = Œ±_total * f(t / T)
```

Common spending functions:
- **O'Brien-Fleming**: Conservative early, liberal late
- **Pocock**: Uniform spending
- **Linear**: Proportional to time

**Always-Valid Inference**: Safe p-values at any stopping time
- Use mixture sequential probability ratio test (mSPRT)
- Or: Conservative confidence sequences

### Global Holdouts

- Per-project: 5-10% users never receive experiments
- Used for unbiased policy evaluation
- Refreshed quarterly to avoid selection bias

---

## üìä Data Model

### Events Table
```sql
CREATE TABLE events (
  event_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id TEXT NOT NULL,
  user_id TEXT,
  anon_id TEXT,
  ts TIMESTAMPTZ NOT NULL,
  name TEXT NOT NULL,
  props JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_events_project_ts ON events(project_id, ts DESC);
CREATE INDEX idx_events_user ON events(project_id, user_id, ts DESC);
CREATE INDEX idx_events_props ON events USING GIN(props);

-- Partition by month
ALTER TABLE events PARTITION BY RANGE (ts);
```

### Model Configs
```sql
CREATE TABLE model_configs (
  config_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id TEXT NOT NULL,
  model_type TEXT NOT NULL, -- 'ohm_simple', 'rc_retention', 'state_space'
  hyperparams JSONB NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Estimate Runs
```sql
CREATE TABLE estimate_runs (
  run_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id TEXT NOT NULL,
  segment TEXT,
  model_type TEXT,
  params JSONB NOT NULL, -- {A, B, C, D, Q, R, R_val, C_val, RC}
  fit JSONB NOT NULL,    -- {rmse, r2, log_likelihood}
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_estimate_runs_project ON estimate_runs(project_id, created_at DESC);
```

### Simulation Runs
```sql
CREATE TABLE simulation_runs (
  run_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id TEXT NOT NULL,
  request JSONB NOT NULL,  -- Full request payload
  result JSONB NOT NULL,   -- KPI trajectories, confidence bands
  status TEXT,             -- 'completed', 'failed'
  duration_ms INTEGER,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_sim_runs_project ON simulation_runs(project_id, created_at DESC);
```

### Segments
```sql
CREATE TABLE segments (
  segment_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id TEXT NOT NULL,
  name TEXT NOT NULL,
  filter TEXT NOT NULL, -- SQL WHERE clause or JSONB filter DSL
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(project_id, name)
);
```

---

## üèóÔ∏è Architecture

### API Layer
- **Framework**: FastAPI (Python) or Next.js (Node + tRPC)
- **Auth**: JWT with project-scoped claims
- **Rate Limits**: Token bucket (default 100 QPS/project, burst 200)
- **Idempotency**: `Idempotency-Key` header, 24h dedup window

### Compute Layer
- **Language**: Python 3.11+
- **Libraries**: JAX, NumPy, SciPy, scikit-learn
- **Queue**: RabbitMQ, SQS, or Redis Streams
- **Workers**: Celery or Arq for async jobs

**Hot Path** (< 100ms):
- `/events` ingestion
- `/estimate` retrieval (cached)
- `/jobs/{id}` status poll

**Cold Path** (seconds):
- `/estimate` (EM fit)
- `/simulate` (long horizon)
- `/recommend` (MPC solve)
- `/forecast` (Monte Carlo)

### Storage
- **Postgres**: Events (partitioned), configs, runs
- **ClickHouse**: Alternative for high-volume events (100M+/day)
- **Redis**: Cache for recent estimates, rate limits
- **S3/R2**: Long-term storage for run artifacts

### Observability
- **Metrics**: Prometheus (request latency, queue depth, fit RMSE)
- **Logs**: Structured JSON via Winston/Bunyan
- **Traces**: OpenTelemetry to Jaeger/Tempo
- **Alerts**: PagerDuty for SLO violations

---

## ‚ö° Performance Targets

| Endpoint | p50 | p95 | p99 |
|----------|-----|-----|-----|
| POST /events | 20ms | 50ms | 100ms |
| POST /estimate (cached) | 10ms | 30ms | 50ms |
| POST /estimate (fresh) | 500ms | 2s | 5s |
| POST /simulate (H=7) | 100ms | 300ms | 600ms |
| POST /simulate (H=28) | 400ms | 1s | 2s |
| POST /recommend | 200ms | 500ms | 1s |
| POST /forecast | 300ms | 800ms | 1.5s |

**Async Mode**: Return `202 Accepted` + `/jobs/{id}` for long ops

---

## üîß Deployment

### Infrastructure
```yaml
# docker-compose.yml
services:
  api:
    image: everreach/electro-api:latest
    ports: ["8000:8000"]
    environment:
      DATABASE_URL: postgres://...
      REDIS_URL: redis://...
      QUEUE_URL: amqp://...
  
  worker:
    image: everreach/electro-worker:latest
    command: celery -A tasks worker -l info
    environment:
      DATABASE_URL: postgres://...
      REDIS_URL: redis://...
  
  postgres:
    image: postgres:16
    volumes: ["pgdata:/var/lib/postgresql/data"]
  
  redis:
    image: redis:7
  
  rabbitmq:
    image: rabbitmq:3-management
```

### Environment Variables
```bash
DATABASE_URL=postgresql://user:pass@host:5432/electro
REDIS_URL=redis://localhost:6379/0
QUEUE_URL=amqp://guest:guest@localhost:5672/
OPENAI_API_KEY=sk-...
SENTRY_DSN=https://...
LOG_LEVEL=info
ENVIRONMENT=production
```

### Migrations
```bash
# Alembic for Postgres schema
alembic upgrade head

# Or raw SQL
psql $DATABASE_URL -f migrations/001_init_schema.sql
```

---

## üß™ Testing Strategy

### Unit Tests
- Pure math functions (Kalman, EM, MPC)
- Input validation
- Constraint checking
- >90% coverage target

### Integration Tests
- End-to-end flow: ingest ‚Üí estimate ‚Üí simulate ‚Üí recommend
- Database round-trips
- Queue delivery
- Idempotency checks

### Performance Tests
- Throughput: 1000 events/sec ingestion
- Latency: p95 under load
- Scalability: 10K concurrent simulations

### Validation Tests
- Synthetic data with known parameters ‚Üí recover within 5%
- Holdout validation: RMSE on unseen test set
- A/B test replication: compare to historical results

---

## üìö References

### Academic Papers
1. **Kalman Filtering**: Kalman (1960), "A New Approach to Linear Filtering"
2. **EM Algorithm**: Dempster et al. (1977), "Maximum Likelihood from Incomplete Data"
3. **MPC**: Maciejowski (2002), "Predictive Control with Constraints"
4. **Doubly-Robust**: Bang & Robins (2005), "Doubly Robust Estimation"
5. **Constrained Bandits**: Badanidiyuru et al. (2013), "Bandits with Knapsacks"
6. **Sequential Testing**: Johari et al. (2022), "Always Valid Inference"

### Libraries & Tools
- **JAX**: Google's autodiff + JIT compiler
- **NumPyro**: Probabilistic programming on JAX
- **CVXPY**: Convex optimization DSL
- **scikit-learn**: ML utilities (Ridge, Logistic)
- **EconML**: Causal inference toolkit (Microsoft)

---

## üöÄ Next Steps

1. **Prototype**: Implement segments 1-6 in `backend-vercel/lib/electro-behavior/`
2. **Validate**: Run on synthetic + real EverReach data
3. **API**: Expose `/estimate`, `/simulate`, `/recommend` via FastAPI
4. **Dashboard**: Build scenario explorer UI
5. **Alpha**: Onboard 3 design partners
6. **Scale**: Optimize for 100M events/day, deploy on Fly/Railway

---

**Status**: Math proven, code ready, ship it! üö¢
